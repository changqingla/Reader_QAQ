"""
æµ‹è¯• RAG æœåŠ¡çš„å“åº”æ ¼å¼
åˆ†åˆ«æµ‹è¯•æ·±åº¦æ€è€ƒæ¨¡å¼å’Œè”ç½‘æœç´¢æ¨¡å¼
"""
import asyncio
import logging
import json
import httpx
from .config import rag_settings

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


async def test_deep_thinking_mode():
    """æµ‹è¯•æ·±åº¦æ€è€ƒæ¨¡å¼çš„å“åº”æ ¼å¼"""
    
    logger.info("\n" + "=" * 80)
    logger.info("æµ‹è¯• 1: æ·±åº¦æ€è€ƒæ¨¡å¼ (thinking=true)")
    logger.info("=" * 80)
    
    url = f"{rag_settings.RAG_SERVICE_URL}/conversation"
    
    request_data = {
        "mode": "chat",
        "session_id": "test-deep-001",
        "messages": [
            {"role": "user", "content": "ä»‹ç»ä¸€ä¸‹æ­å·"}
        ],
        "llm": {
            "model_name": rag_settings.LLM_MODEL_NAME,
            "model_url": rag_settings.LLM_MODEL_URL,
            "api_key": rag_settings.LLM_API_KEY,
            "temperature": 0.7,
            "top_p": 0.3,
            "max_tokens": 500
        },
        "recall": {
            "index_names": ["test-index"],
            "es_host": rag_settings.ES_HOST,
            "top_n": 8,
            "similarity_threshold": 0.2,
            "vector_similarity_weight": 0.3,
            "top_k": 1024,
            "model_factory": rag_settings.EMBED_MODEL_FACTORY,
            "model_name": rag_settings.EMBED_MODEL_NAME,
            "model_base_url": rag_settings.EMBED_MODEL_BASE_URL,
            "model_api_key": rag_settings.EMBED_MODEL_API_KEY,
            "rerank_factory": rag_settings.RERANK_FACTORY,
            "rerank_model_name": rag_settings.RERANK_MODEL_NAME,
            "rerank_base_url": rag_settings.RERANK_BASE_URL,
            "rerank_api_key": rag_settings.RERANK_API_KEY
        },
        "thinking": {
            "max_sub_questions": 4,
            "max_iterations": 2,
            "enable_question_refinement": True
        },
        "knowledge_base": True,
        "tavily": False,
        "show_quote": True,
        "stream": True
    }
    
    logger.info(f"\nğŸ“¡ è¯·æ±‚ URL: {url}")
    logger.info(f"ğŸ’­ æ·±åº¦æ€è€ƒ: å¯ç”¨")
    logger.info("\nå¼€å§‹æ¥æ”¶å“åº”...\n")
    logger.info("-" * 80)
    
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            async with client.stream(
                "POST",
                url,
                json=request_data,
                headers={
                    "AgentAuthorization": f"Bearer {rag_settings.RAG_AGENT_AUTHORIZATION.replace('Bearer ', '')}",
                    "Content-Type": "application/json"
                }
            ) as response:
                response.raise_for_status()
                
                chunk_count = 0
                async for line in response.aiter_lines():
                    if not line.strip() or not line.startswith("data: "):
                        continue
                    
                    data = line[6:]  # Remove "data: " prefix
                    
                    if data == "[DONE]":
                        logger.info("\n\nâœ… æ”¶åˆ° [DONE] æ ‡è®°")
                        break
                    
                    try:
                        chunk_data = json.loads(data)
                        chunk_count += 1
                        
                        # æ‰“å°åŸå§‹å“åº”æ ¼å¼
                        logger.info(f"\nğŸ“¦ Chunk {chunk_count}:")
                        logger.info(f"   åŸå§‹æ•°æ®: {json.dumps(chunk_data, ensure_ascii=False, indent=2)}")
                        
                    except json.JSONDecodeError as e:
                        logger.warning(f"æ— æ³•è§£æ JSON: {data}")
                
                logger.info(f"\n\nğŸ“Š æ€»å…±æ”¶åˆ° {chunk_count} ä¸ªæ•°æ®å—")
                
    except Exception as e:
        logger.error(f"\nâŒ é”™è¯¯: {e}", exc_info=True)


async def test_search_mode():
    """æµ‹è¯•è”ç½‘æœç´¢æ¨¡å¼çš„å“åº”æ ¼å¼"""
    
    logger.info("\n\n" + "=" * 80)
    logger.info("æµ‹è¯• 2: è”ç½‘æœç´¢æ¨¡å¼ (tavily=true)")
    logger.info("=" * 80)
    
    url = f"{rag_settings.RAG_SERVICE_URL}/conversation"
    
    request_data = {
        "mode": "search",
        "session_id": "test-search-001",
        "messages": [
            {"role": "user", "content": "ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·"}
        ],
        "llm": {
            "model_name": rag_settings.LLM_MODEL_NAME,
            "model_url": rag_settings.LLM_MODEL_URL,
            "api_key": rag_settings.LLM_API_KEY,
            "temperature": 0.7,
            "top_p": 0.3,
            "max_tokens": 500
        },
        "recall": {
            "index_names": ["test-index"],
            "es_host": rag_settings.ES_HOST,
            "top_n": 8,
            "similarity_threshold": 0.2,
            "vector_similarity_weight": 0.3,
            "top_k": 1024,
            "model_factory": rag_settings.EMBED_MODEL_FACTORY,
            "model_name": rag_settings.EMBED_MODEL_NAME,
            "model_base_url": rag_settings.EMBED_MODEL_BASE_URL,
            "model_api_key": rag_settings.EMBED_MODEL_API_KEY,
            "rerank_factory": rag_settings.RERANK_FACTORY,
            "rerank_model_name": rag_settings.RERANK_MODEL_NAME,
            "rerank_base_url": rag_settings.RERANK_BASE_URL,
            "rerank_api_key": rag_settings.RERANK_API_KEY
        },
        "thinking": {
            "max_sub_questions": 4,
            "max_iterations": 2,
            "enable_question_refinement": True
        },
        "knowledge_base": False,
        "tavily": True,
        "tavily_api_key": rag_settings.TAVILY_API_KEY,
        "show_quote": True,
        "stream": True
    }
    
    logger.info(f"\nğŸ“¡ è¯·æ±‚ URL: {url}")
    logger.info(f"ğŸ” è”ç½‘æœç´¢: å¯ç”¨")
    logger.info("\nå¼€å§‹æ¥æ”¶å“åº”...\n")
    logger.info("-" * 80)
    
    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            async with client.stream(
                "POST",
                url,
                json=request_data,
                headers={
                    "AgentAuthorization": f"Bearer {rag_settings.RAG_AGENT_AUTHORIZATION.replace('Bearer ', '')}",
                    "Content-Type": "application/json"
                }
            ) as response:
                response.raise_for_status()
                
                chunk_count = 0
                async for line in response.aiter_lines():
                    if not line.strip() or not line.startswith("data: "):
                        continue
                    
                    data = line[6:]  # Remove "data: " prefix
                    
                    if data == "[DONE]":
                        logger.info("\n\nâœ… æ”¶åˆ° [DONE] æ ‡è®°")
                        break
                    
                    try:
                        chunk_data = json.loads(data)
                        chunk_count += 1
                        
                        # æ‰“å°åŸå§‹å“åº”æ ¼å¼
                        logger.info(f"\nğŸ“¦ Chunk {chunk_count}:")
                        logger.info(f"   åŸå§‹æ•°æ®: {json.dumps(chunk_data, ensure_ascii=False, indent=2)}")
                        
                    except json.JSONDecodeError as e:
                        logger.warning(f"æ— æ³•è§£æ JSON: {data}")
                
                logger.info(f"\n\nğŸ“Š æ€»å…±æ”¶åˆ° {chunk_count} ä¸ªæ•°æ®å—")
                
    except Exception as e:
        logger.error(f"\nâŒ é”™è¯¯: {e}", exc_info=True)


async def main():
    """ä¸»å‡½æ•°"""
    
    logger.info("\nğŸ§ª å¼€å§‹æµ‹è¯• RAG æœåŠ¡å“åº”æ ¼å¼")
    logger.info(f"ğŸ“¡ æœåŠ¡åœ°å€: {rag_settings.RAG_SERVICE_URL}")
    
    # æµ‹è¯•æ·±åº¦æ€è€ƒæ¨¡å¼
    await test_deep_thinking_mode()
    
    # ç­‰å¾…ä¸€ä¸‹
    await asyncio.sleep(2)
    
    # æµ‹è¯•è”ç½‘æœç´¢æ¨¡å¼
    await test_search_mode()
    
    logger.info("\n\n" + "=" * 80)
    logger.info("âœ… æµ‹è¯•å®Œæˆï¼è¯·æŸ¥çœ‹ä¸Šé¢çš„å“åº”æ ¼å¼")
    logger.info("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())

